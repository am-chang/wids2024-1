{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from category_encoders) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from category_encoders) (1.2.2)\n",
      "Collecting statsmodels>=0.9.0\n",
      "  Downloading statsmodels-0.14.1-cp39-cp39-macosx_11_0_arm64.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.0.5 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from category_encoders) (1.5.3)\n",
      "Collecting patsy>=0.5.1\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from category_encoders) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas>=1.0.5->category_encoders) (2022.7)\n",
      "Requirement already satisfied: six in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from scikit-learn>=0.20.0->category_encoders) (2.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from statsmodels>=0.9.0->category_encoders) (23.0)\n",
      "Installing collected packages: patsy, statsmodels, category_encoders\n",
      "Successfully installed category_encoders-2.6.3 patsy-0.5.6 statsmodels-0.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from xgboost) (1.10.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.2-cp39-cp39-macosx_11_0_universal2.whl (25.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: plotly in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: pandas>=0.24 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: matplotlib in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: six in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from pandas>=0.24->catboost) (2022.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (23.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (9.4.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (5.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from plotly->catboost) (8.2.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.11.0)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.2 graphviz-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2760538136.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    brew install libomp\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "brew install libomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.3.0.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Users/angelachang/anaconda3/envs/tf/lib/python3.9/site-packages (from lightgbm) (1.10.1)\n",
      "Building wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for lightgbm \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[42 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2024-02-21 20:51:48,494 - scikit_build_core - INFO - RUN: /private/var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/pip-build-env-nbvlvj02/normal/lib/python3.9/site-packages/cmake/data/bin/cmake --version\n",
      "  \u001b[31m   \u001b[0m 2024-02-21 20:51:48,500 - scikit_build_core - INFO - CMake version: 3.28.3\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1m\u001b[92mscikit-build-core 0.8.1\u001b[0m using \u001b[94mCMake 3.28.3\u001b[0m \u001b[91m(wheel)\u001b[0m\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2024-02-21 20:51:48,502 - scikit_build_core - INFO - Build directory: /private/var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/tmpu5o1qf37/build\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1mConfiguring CMake...\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2024-02-21 20:51:48,511 - scikit_build_core - INFO - RUN: /private/var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/pip-build-env-nbvlvj02/normal/lib/python3.9/site-packages/ninja/data/bin/ninja --version\n",
      "  \u001b[31m   \u001b[0m 2024-02-21 20:51:48,554 - scikit_build_core - INFO - Ninja version: 1.11.1\n",
      "  \u001b[31m   \u001b[0m 2024-02-21 20:51:48,554 - scikit_build_core - WARNING - libdir/ldlibrary: /Users/angelachang/anaconda3/envs/tf/lib/libpython3.9.a is not a real file!\n",
      "  \u001b[31m   \u001b[0m 2024-02-21 20:51:48,554 - scikit_build_core - WARNING - Can't find a Python library, got libdir=/Users/angelachang/anaconda3/envs/tf/lib, ldlibrary=libpython3.9.a, multiarch=darwin, masd=None\n",
      "  \u001b[31m   \u001b[0m 2024-02-21 20:51:48,555 - scikit_build_core - INFO - RUN: /private/var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/pip-build-env-nbvlvj02/normal/lib/python3.9/site-packages/cmake/data/bin/cmake -S. -B/var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/tmpu5o1qf37/build -DCMAKE_BUILD_TYPE:STRING=Release -C/var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/tmpu5o1qf37/build/CMakeInit.txt -DCMAKE_MAKE_PROGRAM=/private/var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/pip-build-env-nbvlvj02/normal/lib/python3.9/site-packages/ninja/data/bin/ninja -D__BUILD_FOR_PYTHON:BOOL=ON\n",
      "  \u001b[31m   \u001b[0m loading initial cache file /var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/tmpu5o1qf37/build/CMakeInit.txt\n",
      "  \u001b[31m   \u001b[0m -- The C compiler identification is AppleClang 13.1.6.13160021\n",
      "  \u001b[31m   \u001b[0m -- The CXX compiler identification is AppleClang 13.1.6.13160021\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working C compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting C compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compiler ABI info - done\n",
      "  \u001b[31m   \u001b[0m -- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ - skipped\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features\n",
      "  \u001b[31m   \u001b[0m -- Detecting CXX compile features - done\n",
      "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP_C (missing: OpenMP_C_FLAGS OpenMP_C_LIB_NAMES)\n",
      "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP_CXX (missing: OpenMP_CXX_FLAGS OpenMP_CXX_LIB_NAMES)\n",
      "  \u001b[31m   \u001b[0m -- Could NOT find OpenMP (missing: OpenMP_C_FOUND OpenMP_CXX_FOUND)\n",
      "  \u001b[31m   \u001b[0m -- Found OpenMP_C: -Xpreprocessor -fopenmp -I/include\n",
      "  \u001b[31m   \u001b[0m -- Found OpenMP_CXX: -Xpreprocessor -fopenmp -I/include\n",
      "  \u001b[31m   \u001b[0m -- Found OpenMP: TRUE\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_PREFETCH\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_PREFETCH - Failed\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_MALLOC\n",
      "  \u001b[31m   \u001b[0m -- Performing Test MM_MALLOC - Success\n",
      "  \u001b[31m   \u001b[0m -- Using _mm_malloc\n",
      "  \u001b[31m   \u001b[0m -- Configuring done (12.8s)\n",
      "  \u001b[31m   \u001b[0m -- Generating done (0.0s)\n",
      "  \u001b[31m   \u001b[0m -- Build files have been written to: /var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/tmpu5o1qf37/build\n",
      "  \u001b[31m   \u001b[0m \u001b[92m***\u001b[0m \u001b[1mBuilding project with \u001b[94mNinja\u001b[0m...\u001b[0m\n",
      "  \u001b[31m   \u001b[0m 2024-02-21 20:52:01,376 - scikit_build_core - INFO - RUN: /private/var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/pip-build-env-nbvlvj02/normal/lib/python3.9/site-packages/cmake/data/bin/cmake --build /var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/tmpu5o1qf37/build\n",
      "  \u001b[31m   \u001b[0m ninja: error: '/lib/libomp.dylib', needed by '/private/var/folders/b1/zqzn387j6zd37gnn4xj6ym200000gn/T/pip-install-lz3wzfgj/lightgbm_2270ea9ff3074cb783f54ee0532e6d40/lib_lightgbm.so', missing and no known rule to make it\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[91m\u001b[1m*** CMake build failed\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for lightgbm\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build lightgbm\n",
      "\u001b[31mERROR: Could not build wheels for lightgbm, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhierarchy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dendrogram, linkage\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m squareform\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier, Pool\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "#import optuna\n",
    "from category_encoders import OneHotEncoder, MEstimateEncoder, CatBoostEncoder, OrdinalEncoder\n",
    "from sklearn import set_config\n",
    "import category_encoders\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, make_scorer, f1_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.preprocessing import FunctionTransformer,StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import auc, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data here\n",
    "train = pd.read_csv('data/training.csv')\n",
    "test = pd.read_csv('data/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cat and numeric columns\n",
    "num_cols = train.select_dtypes('number').columns.tolist()\n",
    "target = 'DiagPeriodL90D'\n",
    "cat_cols = [c for c in train.columns if c not in num_cols and c != 'DiagPeriodL90D']\n",
    "num_cols.remove('DiagPeriodL90D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure numeric cols doesn't have numeric categories\n",
    "train[num_cols]\n",
    "\n",
    "# apparently patient_id, patient_zip3 are cat cols\n",
    "cat_cols.extend(['patient_id', 'patient_zip3'])\n",
    "num_cols.remove('patient_id')\n",
    "num_cols.remove('patient_zip3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseEstimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# drop column here, example of dropping  bmi\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDropColumns\u001b[39;00m(\u001b[43mBaseEstimator\u001b[49m,TransformerMixin):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
     ]
    }
   ],
   "source": [
    "# drop column here, example of dropping  bmi\n",
    "class DropColumns(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        x_copy = X.copy()        \n",
    "        x_copy = x_copy.drop('bmi',axis=1) # drop column here\n",
    "        return x_copy\n",
    "    \n",
    "# add column here, example of adding an all-one colum \n",
    "class AddColumns(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        x_copy = X.copy()        \n",
    "        # x_copy['all_one'] = np.ones(len(x_copy)) # add column here\n",
    "        return x_copy\n",
    "    \n",
    "# self-define missing value class   \n",
    "class InputCol(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        x_copy = X.copy()   \n",
    "        return x_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cs/Desktop/widsdatathon2024-challenge1/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:343: UserWarning: With transform=\"pandas\", `func` should return a DataFrame to follow the set_output API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ImputeCatCols(d):\n",
    "    df = d.copy()\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].fillna('None')\n",
    "    return df\n",
    "\n",
    "num_transformer = Pipeline([('imputer',SimpleImputer(strategy='mean')), # set missing data to mean, other options are KNNImputer(n_neighbors=2)\n",
    "                             ('scaler',StandardScaler())])\n",
    "cat_transformer = Pipeline([('imputer',FunctionTransformer(ImputeCatCols)), \n",
    "                             ('cat',CatBoostEncoder())])\n",
    "\n",
    "preprocess = ColumnTransformer([('num',num_transformer,num_cols),\n",
    "                                ('cat',cat_transformer,cat_cols)],\n",
    "                                remainder='passthrough',\n",
    "                                verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "\n",
    "preprocess_catboost= Pipeline([('preprocess',preprocess),\n",
    "                           ('drop',DropColumns())  # add or drop column here\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer_2= Pipeline([('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                           ('cat',LabelEncoder())])\n",
    "num_transformer_2 = Pipeline([('imputer',SimpleImputer(strategy='most_frequent'))])\n",
    "preprocess_3 = ColumnTransformer([('cat',cat_transformer_2,cat_cols),\n",
    "                                            ('num',num_transformer_2,num_cols)\n",
    "                                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, label):\n",
    "    \n",
    "    print('model: {}'.format(label))\n",
    "    X = train.copy()\n",
    "    y = X.pop(target)\n",
    "              \n",
    "    skf = StratifiedKFold(n_splits=5,random_state=SEED, shuffle=True)\n",
    "    \n",
    "    val_predictions = np.zeros(len(train))\n",
    "    score_list = []\n",
    "    for fold, (trx_idx, val_idx) in enumerate(skf.split(X,y)):\n",
    "        X_train = X.iloc[trx_idx]\n",
    "        y_train = y.iloc[trx_idx]\n",
    "        X_val   = X.iloc[val_idx]\n",
    "        y_val   = y.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred_train = model.predict_proba(X_train)[:,1]\n",
    "        y_pred_val   = model.predict_proba(X_val)[:,1]\n",
    "        auc_train = roc_auc_score(y_train,y_pred_train)\n",
    "        auc_val   = roc_auc_score(y_val,y_pred_val)\n",
    "        \n",
    "        val_predictions[val_idx] = y_pred_val\n",
    "        score_list.append(auc_val)\n",
    "        print(f'fold: {fold} - AUC Train: {auc_train} - AUC Val {auc_val}') \n",
    "\n",
    "    print(f'AUC MEAN {np.mean(score_list)} - Std: {np.std(score_list)}')  \n",
    "    \n",
    "    return score_list, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "\n",
    "params_cat = {'learning_rate': 0.004, \n",
    "              'iterations': 1000,\n",
    "              'max_depth': 5, \n",
    "              'subsample': 0.7401131867566202, \n",
    "              'colsample_bylevel': 0.29684187768021997, \n",
    "              'min_data_in_leaf': 47,\n",
    "              'logging_level': 'Silent'}\n",
    "\n",
    "params_lgb= {'learning_rate': 0.0016,\n",
    "             'subsample': 0.6710494933148675, \n",
    "             'colsample_bytree': 0.7929648706646588, \n",
    "             'num_leaves': 29,\n",
    "             'verbose':-1}\n",
    "\n",
    "\n",
    "params_xbg = {'learning_rate': 0.001, \n",
    "              'max_depth': 6, \n",
    "              'subsample': 0.5281085467708261, \n",
    "              'min_child_weight': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: RF\n",
      "fold: 0 - AUC Train: 0.8502600865669502 - AUC Val 0.8010395615359034\n",
      "fold: 1 - AUC Train: 0.8535540329460948 - AUC Val 0.7977654689928734\n",
      "fold: 2 - AUC Train: 0.8528011997009787 - AUC Val 0.8078609986504722\n",
      "fold: 3 - AUC Train: 0.8538171445651039 - AUC Val 0.7887176158173861\n",
      "fold: 4 - AUC Train: 0.8595907395270574 - AUC Val 0.7779822128668629\n",
      "AUC MEAN 0.7946731715726997 - Std: 0.010373704780898897\n",
      "model: lgbm\n",
      "fold: 0 - AUC Train: 0.835387853962925 - AUC Val 0.7981296845821287\n",
      "fold: 1 - AUC Train: 0.8329491430341565 - AUC Val 0.7884986696781364\n",
      "fold: 2 - AUC Train: 0.8297525018704827 - AUC Val 0.81016761543327\n",
      "fold: 3 - AUC Train: 0.8410855823393162 - AUC Val 0.7862266233383781\n",
      "fold: 4 - AUC Train: 0.8363818346218169 - AUC Val 0.780086528538541\n",
      "AUC MEAN 0.7926218243140909 - Std: 0.010518782729787355\n",
      "model: Extratrees\n",
      "fold: 0 - AUC Train: 0.8797669399972344 - AUC Val 0.7986371543321993\n",
      "fold: 1 - AUC Train: 0.8792950296685101 - AUC Val 0.8030723520961212\n",
      "fold: 2 - AUC Train: 0.8775183312095063 - AUC Val 0.8059932344362586\n",
      "fold: 3 - AUC Train: 0.8812660767099475 - AUC Val 0.7876741005923069\n",
      "fold: 4 - AUC Train: 0.8828223254338912 - AUC Val 0.7759870501681148\n",
      "AUC MEAN 0.7942727783250001 - Std: 0.011061281752030408\n",
      "model: XGB\n",
      "fold: 0 - AUC Train: 0.833646808027769 - AUC Val 0.8011383694456525\n",
      "fold: 1 - AUC Train: 0.8348858285581893 - AUC Val 0.7978381309425951\n",
      "fold: 2 - AUC Train: 0.8330514075501575 - AUC Val 0.8136076946123886\n",
      "fold: 3 - AUC Train: 0.8356692231528944 - AUC Val 0.783834860834761\n",
      "fold: 4 - AUC Train: 0.8402403250127526 - AUC Val 0.7808000240712715\n",
      "AUC MEAN 0.7954438159813337 - Std: 0.011977442559375854\n"
     ]
    }
   ],
   "source": [
    "score_list, oof_list= pd.DataFrame(), pd.DataFrame()\n",
    "models = [          \n",
    "        #    ('catBoost',make_pipeline(preprocess_catboost,\n",
    "        #                             CatBoostClassifier(cat_features=cat_cols,\n",
    "        #                                                **params_cat,\n",
    "        #                                                random_state=SEED))),                                       \n",
    "                            \n",
    "           ('RF',make_pipeline(preprocess_othermodels,\n",
    "                               RandomForestClassifier(n_estimators=200,\n",
    "                                                      random_state=SEED,\n",
    "                                                      min_samples_leaf=92,\n",
    "                                                      max_features=1.0))),\n",
    "                                                      \n",
    "            ('lgbm',make_pipeline(preprocess_othermodels,\n",
    "                                 LGBMClassifier(**params_lgb,\n",
    "                                                random_state=SEED))),  \n",
    "                                                \n",
    "           ('Extratrees',make_pipeline(preprocess_othermodels,\n",
    "                                       ExtraTreesClassifier(n_estimators=300,\n",
    "                                                           random_state=SEED,\n",
    "                                                           min_samples_leaf=46,\n",
    "                                                           max_features=1.0))),\n",
    "           ('XGB',make_pipeline(preprocess_othermodels,\n",
    "                                 XGBClassifier(**params_xbg,random_state=SEED)))                                        \n",
    "\n",
    "            \n",
    "        ]\n",
    "for label, model in models:\n",
    "    score_list[label], oof_list[label] = score_model(model,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69988248, 0.66836308, 0.67904398, ..., 0.75151407, 0.2886226 ,\n",
       "       0.71415358])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voting from all models\n",
    "w = RidgeClassifier().fit(oof_list,train.DiagPeriodL90D).coef_[0]\n",
    "voter = VotingClassifier(models, weights = w, voting = 'soft')\n",
    "\n",
    "X = train.copy()\n",
    "y = X.pop('DiagPeriodL90D')      \n",
    "                       \n",
    "voter.fit(X,y)\n",
    "voter.predict_proba(test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
