{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import optuna\n",
    "from category_encoders import OneHotEncoder, MEstimateEncoder, CatBoostEncoder, OrdinalEncoder\n",
    "from sklearn import set_config\n",
    "import category_encoders\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, make_scorer, f1_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone, OneToOneFeatureMixin\n",
    "from sklearn.preprocessing import FunctionTransformer,StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import auc, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data here\n",
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cat and numeric columns\n",
    "num_cols = train.select_dtypes('number').columns.tolist()\n",
    "target = 'DiagPeriodL90D'\n",
    "cat_cols = [c for c in train.columns if c not in num_cols and c != 'DiagPeriodL90D']\n",
    "num_cols.remove('DiagPeriodL90D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure numeric cols doesn't have numeric categories\n",
    "# Note: when adding or removing columns in the self-defined class, edit num_cols and cat_cols\n",
    "\n",
    "# apparently patient_id, patient_zip3 are cat cols\n",
    "cat_cols.extend(['patient_id', 'patient_zip3'])\n",
    "num_cols.remove('patient_id')\n",
    "num_cols.remove('patient_zip3')\n",
    "\n",
    "#drop bmi\n",
    "num_cols.remove('bmi')\n",
    "\n",
    "# add code_counts, tumor_loc, common_code\n",
    "num_cols.append('code_counts')\n",
    "cat_cols.extend(['tumor_loc', 'common_code'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column here, example of dropping  bmi\n",
    "class DropColumns(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        x_copy = X.copy()        \n",
    "        x_copy = x_copy.drop('bmi',axis=1) # drop column here\n",
    "        return x_copy\n",
    "\n",
    "\n",
    "# add column here, example of adding an all-one colum \n",
    "class AddColumns(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        x_copy = X.copy()\n",
    "        tumor_loc_list = []\n",
    "\n",
    "        for i in x_copy['breast_cancer_diagnosis_desc']:\n",
    "            if 'left' in i:\n",
    "                tumor_loc_list.append('Left')\n",
    "            elif 'right' in i:\n",
    "                tumor_loc_list.append('Right')\n",
    "            else:\n",
    "                tumor_loc_list.append('Unspecified')\n",
    "\n",
    "        x_copy['tumor_loc'] = tumor_loc_list\n",
    "    \n",
    "        # Add the common vs. uncommon code cols\n",
    "        # Create a dictionary mapping diagnosis code to the frequency\n",
    "        code_counts = Counter(x_copy['breast_cancer_diagnosis_code'])\n",
    "\n",
    "        # Loop through the codes in the dataset to map the frequency then attach to the df\n",
    "        code_freq_list = [code_counts[i] for i in x_copy['breast_cancer_diagnosis_code']]\n",
    "        x_copy['code_counts'] = code_freq_list\n",
    "\n",
    "        # Create another variable classifying if the code is common or uncommon\n",
    "        x_copy['common_code'] = np.where(\n",
    "            x_copy['code_counts']>=np.mean(x_copy['code_counts']),\n",
    "            'Common', 'Uncommon')\n",
    "        return x_copy\n",
    "\n",
    "    \n",
    "# self-define missing value class   \n",
    "class InputCol(OneToOneFeatureMixin, TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        x_copy = X.copy()   \n",
    "        x_copy['patient_race'] = np.where((x_copy['patient_race'] == 'None') & (x_copy['race_white'] > 90.00), 'White', x_copy['patient_race'])\n",
    "        x_copy['patient_race'] = np.where((x_copy['patient_race'] == 'None') & (x_copy['hispanic'] > 90.00), 'Hispanic', x_copy['patient_race'])\n",
    "        x_copy['payer_type'] = np.where((x_copy['payer_type'] == 'None') & (x_copy['patient_age'] >= 75), 'MEDICARE ADVANTAGE', x_copy['payer_type'])\n",
    "\n",
    "        return x_copy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer design\n",
    "\n",
    "def ImputeCatCols(d):\n",
    "    df = d.copy()\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].fillna('None')\n",
    "    return df\n",
    "\n",
    "cat_transformer = Pipeline([('imputer',FunctionTransformer(ImputeCatCols))])\n",
    "\n",
    "num_transformer = Pipeline([('imputer',SimpleImputer(strategy='mean')),\n",
    "                             ('scaler',StandardScaler())])\n",
    "\n",
    "\n",
    "\n",
    "cat_transformer_2= Pipeline([('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                           ('cat',CatBoostEncoder())])\n",
    "num_transformer_2 = Pipeline([('imputer',SimpleImputer(strategy='most_frequent'))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other model preprocess\n",
    "preprocess_1 = Pipeline([('drop', DropColumns()),\n",
    "                                ('add', AddColumns()),\n",
    "                                ('general_input', InputCol())]).set_output(transform='pandas')\n",
    "\n",
    "preprocess_2 = ColumnTransformer([('num',num_transformer_2,num_cols),\n",
    "                                  ('cat',cat_transformer_2,cat_cols)],\n",
    "                                  remainder='passthrough',\n",
    "                                  verbose_feature_names_out=False)\n",
    "\n",
    "preprocess_3 = Pipeline([('p1', preprocess_1), ('p2', preprocess_2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cs/Desktop/widsdatathon2024-challenge1/.conda/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:343: UserWarning: With transform=\"pandas\", `func` should return a DataFrame to follow the set_output API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#catboost\n",
    "preprocess_cat_2 = ColumnTransformer([('num',num_transformer,num_cols),\n",
    "                                  ('cat',cat_transformer,cat_cols)],\n",
    "                                  remainder='passthrough',\n",
    "                                  verbose_feature_names_out=False).set_output(transform='pandas')\n",
    "preprocess_cat_3 = Pipeline([('p1', preprocess_1), ('p2', preprocess_cat_2)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(model, label):\n",
    "    \n",
    "    print('model: {}'.format(label))\n",
    "    X = train.copy()\n",
    "    y = X.pop(target)\n",
    "              \n",
    "    skf = StratifiedKFold(n_splits=5,random_state=SEED, shuffle=True)\n",
    "    \n",
    "    val_predictions = np.zeros(len(train))\n",
    "    score_list = []\n",
    "    for fold, (trx_idx, val_idx) in enumerate(skf.split(X,y)):\n",
    "        X_train = X.iloc[trx_idx]\n",
    "        y_train = y.iloc[trx_idx]\n",
    "        X_val   = X.iloc[val_idx]\n",
    "        y_val   = y.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred_train = model.predict_proba(X_train)[:,1]\n",
    "        y_pred_val   = model.predict_proba(X_val)[:,1]\n",
    "        auc_train = roc_auc_score(y_train,y_pred_train)\n",
    "        auc_val   = roc_auc_score(y_val,y_pred_val)\n",
    "        \n",
    "        val_predictions[val_idx] = y_pred_val\n",
    "        score_list.append(auc_val)\n",
    "        print(f'fold: {fold} - AUC Train: {auc_train} - AUC Val {auc_val}') \n",
    "\n",
    "    print(f'AUC MEAN {np.mean(score_list)} - Std: {np.std(score_list)}')  \n",
    "    \n",
    "    return score_list, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "\n",
    "params_cat = {'learning_rate': 0.004, \n",
    "              'iterations': 1000,\n",
    "              'max_depth': 5, \n",
    "              'subsample': 0.7401131867566202, \n",
    "              'colsample_bylevel': 0.29684187768021997, \n",
    "              'min_data_in_leaf': 47,\n",
    "              'logging_level': 'Silent'}\n",
    "\n",
    "params_lgb= {'learning_rate': 0.0016,\n",
    "             'subsample': 0.6710494933148675, \n",
    "             'colsample_bytree': 0.7929648706646588, \n",
    "             'num_leaves': 29,\n",
    "             'verbose':-1}\n",
    "\n",
    "\n",
    "params_xbg = {'learning_rate': 0.001, \n",
    "              'max_depth': 6, \n",
    "              'subsample': 0.5281085467708261, \n",
    "              'min_child_weight': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patient_race',\n",
       " 'payer_type',\n",
       " 'patient_state',\n",
       " 'patient_gender',\n",
       " 'breast_cancer_diagnosis_code',\n",
       " 'breast_cancer_diagnosis_desc',\n",
       " 'metastatic_cancer_diagnosis_code',\n",
       " 'metastatic_first_novel_treatment',\n",
       " 'metastatic_first_novel_treatment_type',\n",
       " 'Region',\n",
       " 'Division',\n",
       " 'patient_id',\n",
       " 'patient_zip3',\n",
       " 'tumor_loc',\n",
       " 'common_code']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: catBoost\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0 - AUC Train: 0.8443537023664106 - AUC Val 0.809982796551636\n",
      "fold: 1 - AUC Train: 0.838400143750348 - AUC Val 0.7939323110725288\n",
      "fold: 2 - AUC Train: 0.8380597687193867 - AUC Val 0.8132491863142017\n",
      "fold: 3 - AUC Train: 0.8386950567737071 - AUC Val 0.7942117554870975\n",
      "fold: 4 - AUC Train: 0.8434086249248767 - AUC Val 0.7882160242966196\n",
      "AUC MEAN 0.7999184147444167 - Std: 0.00984222120305882\n",
      "model: RF\n",
      "fold: 0 - AUC Train: 0.8522306218262412 - AUC Val 0.8025232790156303\n",
      "fold: 1 - AUC Train: 0.8535817941720307 - AUC Val 0.7962341264049044\n",
      "fold: 2 - AUC Train: 0.8537655222854641 - AUC Val 0.8082736032900818\n",
      "fold: 3 - AUC Train: 0.8535282918093663 - AUC Val 0.7888440540118358\n",
      "fold: 4 - AUC Train: 0.8598641115991683 - AUC Val 0.7786348900275795\n",
      "AUC MEAN 0.7949019905500063 - Std: 0.010392072031986194\n",
      "model: Extratrees\n",
      "fold: 0 - AUC Train: 0.888370498960326 - AUC Val 0.801517932516436\n",
      "fold: 1 - AUC Train: 0.8859882652417931 - AUC Val 0.8001207404732822\n",
      "fold: 2 - AUC Train: 0.8862491567627626 - AUC Val 0.8070335486943896\n",
      "fold: 3 - AUC Train: 0.8890598808843398 - AUC Val 0.7899198990030909\n",
      "fold: 4 - AUC Train: 0.8901437287470615 - AUC Val 0.7790817450135337\n",
      "AUC MEAN 0.7955347731401464 - Std: 0.009912417241617868\n",
      "model: XGB\n",
      "fold: 0 - AUC Train: 0.8289782977641886 - AUC Val 0.8022278145864776\n",
      "fold: 1 - AUC Train: 0.834350404913881 - AUC Val 0.7969386592301801\n",
      "fold: 2 - AUC Train: 0.833107270017044 - AUC Val 0.8144966031338747\n",
      "fold: 3 - AUC Train: 0.834232499707187 - AUC Val 0.7852848988622482\n",
      "fold: 4 - AUC Train: 0.838108830885972 - AUC Val 0.7789220167628238\n",
      "AUC MEAN 0.7955739985151209 - Std: 0.012548741775030165\n"
     ]
    }
   ],
   "source": [
    "score_list, oof_list= pd.DataFrame(), pd.DataFrame()\n",
    "models = [          \n",
    "           ('catBoost',make_pipeline(preprocess_cat_3,\n",
    "                                    CatBoostClassifier(cat_features=cat_cols,\n",
    "                                                       **params_cat,\n",
    "                                                       random_state=SEED))),                                       \n",
    "                            \n",
    "           ('RF',make_pipeline(preprocess_3,\n",
    "                               RandomForestClassifier(n_estimators=200,\n",
    "                                                      random_state=SEED,\n",
    "                                                      min_samples_leaf=92,\n",
    "                                                      max_features=1.0))),\n",
    "           ('Extratrees',make_pipeline(preprocess_3,\n",
    "                                       ExtraTreesClassifier(n_estimators=300,\n",
    "                                                           random_state=SEED,\n",
    "                                                           min_samples_leaf=46,\n",
    "                                                           max_features=1.0))),\n",
    "           ('XGB',make_pipeline(preprocess_3,\n",
    "                                 XGBClassifier(**params_xbg,random_state=SEED)))                                        \n",
    "\n",
    "            \n",
    "        ]\n",
    "for label, model in models:\n",
    "    score_list[label], oof_list[label] = score_model(model,label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting from all models\n",
    "w = RidgeClassifier().fit(oof_list,train.DiagPeriodL90D).coef_[0]\n",
    "voter = VotingClassifier(models, weights = w, voting = 'soft')\n",
    "\n",
    "X = train.copy()\n",
    "y = X.pop('DiagPeriodL90D')      \n",
    "                       \n",
    "voter.fit(X,y)\n",
    "probs = voter.predict_proba(test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate submission file\n",
    "import time\n",
    "timestr = time.strftime(\"%m%d%Y-%H%M%S\")\n",
    "result = pd.DataFrame({'patient_id': test['patient_id'],'DiagPeriodL90D': probs})\n",
    "result.to_csv(f'submission_{timestr}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
